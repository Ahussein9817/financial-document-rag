{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f172c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/alihussein/venv/bin/python -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install langchain langchain-community langchain-openai langchain-text-splitters openai chromadb pypdf python-dotenv pandas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2a6890a-9f50-4569-b75c-8259dd602532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 1.2.10\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /Users/alihussein/venv/lib/python3.10/site-packages\n",
      "Requires: langchain-core, langgraph, pydantic\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4497f395-db9d-40e7-97dc-5b40c1d1243a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/alihussein/venv/bin/python -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install langchain --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "707862a1-f9e9-43e4-8a05-683c43aff9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Imports complete!\n",
      "Current time: 08:37 PM\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Day 2: RAG Pipeline Development\n",
    "Using modern LangChain 1.x approach\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úì Imports complete!\")\n",
    "print(f\"Current time: {datetime.now().strftime('%I:%M %p')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e744ec16-1df7-4824-8c34-f9889c7ef70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vector store...\n",
      "‚úì Vector store loaded!\n",
      "‚úì Total documents: 17306\n",
      "‚úì Test query returned 2 results\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load the vector store we created yesterday\n",
    "\"\"\"\n",
    "\n",
    "print(\"Loading vector store...\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Chroma(\n",
    "    persist_directory='../data/vectorstore',\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "# Quick test\n",
    "test_results = vectorstore.similarity_search(\"revenue\", k=2)\n",
    "print(f\"‚úì Vector store loaded!\")\n",
    "print(f\"‚úì Total documents: {vectorstore._collection.count()}\")\n",
    "print(f\"‚úì Test query returned {len(test_results)} results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85658c34-257f-4276-b894-264fce03e728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì RAG chain created!\n",
      "  LLM: gpt-3.5-turbo\n",
      "  Retrieval: k=4 chunks\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create RAG chain using modern LangChain approach\n",
    "\"\"\"\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# Create prompt template\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Format documents function\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# Create RAG chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"‚úì RAG chain created!\")\n",
    "print(f\"  LLM: gpt-3.5-turbo\")\n",
    "print(f\"  Retrieval: k=4 chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d58b3b2-5d0c-4084-8a90-b01096832eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What was JPMorgan's total revenue in 2024?\n",
      "\n",
      "Answer: $224,532 million\n",
      "\n",
      "Sources:\n",
      "  [1] JPM_10K_2024.pdf (Year: 2024)\n",
      "  [2] JPM_10K_2024.pdf (Year: 2024)\n",
      "  [3] JPM_10K_2024.pdf (Year: 2024)\n",
      "  [4] JPM_10K_2023.pdf (Year: 2023)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test with one question\n",
    "\"\"\"\n",
    "\n",
    "question = \"What was JPMorgan's total revenue in 2024?\"\n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "\n",
    "# Get answer\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "print(f\"Answer: {answer}\")\n",
    "\n",
    "# Get sources separately\n",
    "docs = retriever.invoke(question)\n",
    "print(f\"\\nSources:\")\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"  [{i+1}] {doc.metadata.get('source_file')} \"\n",
    "          f\"(Year: {doc.metadata.get('year')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e3c5fad-b748-4a25-af80-0108207c24fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Helper function ready!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create helper function to ask questions easily\n",
    "\"\"\"\n",
    "\n",
    "def ask_question(question, k=4, verbose=True):\n",
    "    \"\"\"Ask a question and get answer with sources\"\"\"\n",
    "    \n",
    "    # Create retriever with specified k\n",
    "    retriever_temp = vectorstore.as_retriever(search_kwargs={\"k\": k})\n",
    "    \n",
    "    # Create chain\n",
    "    rag_chain_temp = (\n",
    "        {\"context\": retriever_temp | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    # Get answer\n",
    "    answer = rag_chain_temp.invoke(question)\n",
    "    \n",
    "    # Get sources\n",
    "    docs = retriever_temp.invoke(question)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Q: {question}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"\\nA: {answer}\\n\")\n",
    "        print(\"Sources:\")\n",
    "        for i, doc in enumerate(docs):\n",
    "            print(f\"  [{i+1}] {doc.metadata.get('source_file')} \"\n",
    "                  f\"(Ticker: {doc.metadata.get('ticker')}, \"\n",
    "                  f\"Year: {doc.metadata.get('year')})\")\n",
    "    \n",
    "    return {\n",
    "        'question': question,\n",
    "        'answer': answer,\n",
    "        'sources': [\n",
    "            {\n",
    "                'file': doc.metadata.get('source_file'),\n",
    "                'ticker': doc.metadata.get('ticker'),\n",
    "                'year': doc.metadata.get('year')\n",
    "            }\n",
    "            for doc in docs\n",
    "        ],\n",
    "        'k': k\n",
    "    }\n",
    "\n",
    "print(\"‚úì Helper function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "683bcd92-66d3-4c7c-bb58-0d95aa1d216a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 5 simple questions...\n",
      "\n",
      "\n",
      "============================================================\n",
      "Q: What was JPMorgan's total revenue in 2024?\n",
      "============================================================\n",
      "\n",
      "A: $224,532 million\n",
      "\n",
      "Sources:\n",
      "  [1] JPM_10K_2024.pdf (Ticker: JPM, Year: 2024)\n",
      "  [2] JPM_10K_2024.pdf (Ticker: JPM, Year: 2024)\n",
      "  [3] JPM_10K_2024.pdf (Ticker: JPM, Year: 2024)\n",
      "  [4] JPM_10K_2023.pdf (Ticker: JPM, Year: 2023)\n",
      "\n",
      "============================================================\n",
      "Q: What are Bank of America's main business segments?\n",
      "============================================================\n",
      "\n",
      "A: Bank of America's main business segments are Consumer Banking, Global Wealth & Investment Management (GWIM), Global Banking, and Global Markets.\n",
      "\n",
      "Sources:\n",
      "  [1] BAC_10K_2024.pdf (Ticker: BAC, Year: 2024)\n",
      "  [2] BAC_10K_2022.pdf (Ticker: BAC, Year: 2022)\n",
      "  [3] BAC_10K_2023.pdf (Ticker: BAC, Year: 2023)\n",
      "  [4] BAC_10K_2023.pdf (Ticker: BAC, Year: 2023)\n",
      "\n",
      "============================================================\n",
      "Q: What risk factors did Citigroup identify in 2023?\n",
      "============================================================\n",
      "\n",
      "A: Citigroup identified risks related to the amount of leverage in the economy, stress in the property sector, adverse effects on financial markets, negative impacts on global economic growth rates, lower consumer confidence, increased risk of recession in Europe, the U.S., and other countries, potential losses on sale due to CTA losses, goodwill write-offs, and other AOCI loss components.\n",
      "\n",
      "Sources:\n",
      "  [1] C_10K_2024.pdf (Ticker: C, Year: 2024)\n",
      "  [2] C_10K_2023.pdf (Ticker: C, Year: 2023)\n",
      "  [3] C_10K_2022.pdf (Ticker: C, Year: 2022)\n",
      "  [4] C_10K_2024.pdf (Ticker: C, Year: 2024)\n",
      "\n",
      "============================================================\n",
      "Q: How did JPMorgan's net income change from 2023 to 2024?\n",
      "============================================================\n",
      "\n",
      "A: JPMorgan's net income increased from $49.6 billion in 2023 to $57.0 billion in 2024.\n",
      "\n",
      "Sources:\n",
      "  [1] JPM_10K_2023.pdf (Ticker: JPM, Year: 2023)\n",
      "  [2] JPM_10K_2023.pdf (Ticker: JPM, Year: 2023)\n",
      "  [3] JPM_10K_2024.pdf (Ticker: JPM, Year: 2024)\n",
      "  [4] JPM_10K_2025.pdf (Ticker: JPM, Year: 2025)\n",
      "\n",
      "============================================================\n",
      "Q: What is Bank of America's investment banking revenue?\n",
      "============================================================\n",
      "\n",
      "A: Bank of America's investment banking revenue is $1.167 billion in 2023.\n",
      "\n",
      "Sources:\n",
      "  [1] JPM_10K_2023.pdf (Ticker: JPM, Year: 2023)\n",
      "  [2] BAC_10K_2022.pdf (Ticker: BAC, Year: 2022)\n",
      "  [3] BAC_10K_2023.pdf (Ticker: BAC, Year: 2023)\n",
      "  [4] BAC_10K_2024.pdf (Ticker: BAC, Year: 2024)\n",
      "\n",
      "‚úì Tested 5 simple questions!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MORNING TASK: Test with 5 simple questions\n",
    "\"\"\"\n",
    "\n",
    "print(\"Testing 5 simple questions...\\n\")\n",
    "\n",
    "simple_questions = [\n",
    "    \"What was JPMorgan's total revenue in 2024?\",\n",
    "    \"What are Bank of America's main business segments?\",\n",
    "    \"What risk factors did Citigroup identify in 2023?\",\n",
    "    \"How did JPMorgan's net income change from 2023 to 2024?\",\n",
    "    \"What is Bank of America's investment banking revenue?\"\n",
    "]\n",
    "\n",
    "simple_results = []\n",
    "\n",
    "for q in simple_questions:\n",
    "    result = ask_question(q)\n",
    "    simple_results.append(result)\n",
    "\n",
    "print(f\"\\n‚úì Tested {len(simple_questions)} simple questions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92f2c766-7a28-4ae4-9a69-99b2c8692900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 17 diverse questions...\n",
      "(This will take 3-5 minutes)\n",
      "\n",
      "[1/17] What was Citigroup's total assets in 2023?...\n",
      "[2/17] What is JPMorgan's return on equity?...\n",
      "[3/17] What was Bank of America's net interest income in 2024?...\n",
      "[4/17] Compare JPMorgan and Bank of America's revenue growth...\n",
      "[5/17] Which bank had higher trading revenue in 2024?...\n",
      "[6/17] How has JPMorgan's revenue changed from 2023 to 2024?...\n",
      "[7/17] What trends appear in Citigroup's loan portfolio?...\n",
      "[8/17] How has Bank of America's efficiency ratio changed over time...\n",
      "[9/17] What is JPMorgan's digital banking strategy?...\n",
      "[10/17] What are Bank of America's priorities for 2024?...\n",
      "[11/17] What challenges did Citigroup face in 2023?...\n",
      "[12/17] What is JPMorgan's consumer banking revenue?...\n",
      "[13/17] How did Bank of America's wealth management perform in 2024?...\n",
      "[14/17] What are Citigroup's main revenue sources?...\n",
      "[15/17] What is JPMorgan's employee count?...\n",
      "[16/17] What is Bank of America's capital ratio?...\n",
      "[17/17] What is Citigroup's dividend policy?...\n",
      "\n",
      "‚úì Tested 17 diverse questions!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MORNING TASK: Test with 15-20 diverse questions\n",
    "Categories: Factual, Comparative, Trend-based, Qualitative\n",
    "\"\"\"\n",
    "\n",
    "diverse_questions = [\n",
    "    # Factual (Revenue/Financial metrics)\n",
    "    \"What was Citigroup's total assets in 2023?\",\n",
    "    \"What is JPMorgan's return on equity?\",\n",
    "    \"What was Bank of America's net interest income in 2024?\",\n",
    "    \n",
    "    # Comparative (Cross-company)\n",
    "    \"Compare JPMorgan and Bank of America's revenue growth\",\n",
    "    \"Which bank had higher trading revenue in 2024?\",\n",
    "    \n",
    "    # Trend (Year-over-year)\n",
    "    \"How has JPMorgan's revenue changed from 2023 to 2024?\",\n",
    "    \"What trends appear in Citigroup's loan portfolio?\",\n",
    "    \"How has Bank of America's efficiency ratio changed over time?\",\n",
    "    \n",
    "    # Qualitative (Strategy, outlook)\n",
    "    \"What is JPMorgan's digital banking strategy?\",\n",
    "    \"What are Bank of America's priorities for 2024?\",\n",
    "    \"What challenges did Citigroup face in 2023?\",\n",
    "    \n",
    "    # Specific segments\n",
    "    \"What is JPMorgan's consumer banking revenue?\",\n",
    "    \"How did Bank of America's wealth management perform in 2024?\",\n",
    "    \"What are Citigroup's main revenue sources?\",\n",
    "    \n",
    "    # Additional\n",
    "    \"What is JPMorgan's employee count?\",\n",
    "    \"What is Bank of America's capital ratio?\",\n",
    "    \"What is Citigroup's dividend policy?\"\n",
    "]\n",
    "\n",
    "print(f\"Testing {len(diverse_questions)} diverse questions...\")\n",
    "print(\"(This will take 3-5 minutes)\\n\")\n",
    "\n",
    "diverse_results = []\n",
    "\n",
    "for i, q in enumerate(diverse_questions):\n",
    "    print(f\"[{i+1}/{len(diverse_questions)}] {q[:60]}...\")\n",
    "    result = ask_question(q, verbose=False)  # Less verbose for speed\n",
    "    diverse_results.append(result)\n",
    "\n",
    "print(f\"\\n‚úì Tested {len(diverse_questions)} diverse questions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e455fde8-c4fd-4714-b567-9417b1d18acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Summary:\n",
      "  Total questions: 22\n",
      "  Avg answer length: 192 chars\n",
      "  Avg sources per answer: 4.0\n",
      "\n",
      "First 10 results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Answer_Full</th>\n",
       "      <th>Answer_Length</th>\n",
       "      <th>Num_Sources</th>\n",
       "      <th>Primary_Source</th>\n",
       "      <th>Primary_Ticker</th>\n",
       "      <th>Primary_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was JPMorgan's total revenue in 2024?</td>\n",
       "      <td>$224,532 million</td>\n",
       "      <td>$224,532 million</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>JPM_10K_2024.pdf</td>\n",
       "      <td>JPM</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are Bank of America's main business segme...</td>\n",
       "      <td>Bank of America's main business segments are C...</td>\n",
       "      <td>Bank of America's main business segments are C...</td>\n",
       "      <td>144</td>\n",
       "      <td>4</td>\n",
       "      <td>BAC_10K_2024.pdf</td>\n",
       "      <td>BAC</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What risk factors did Citigroup identify in 2023?</td>\n",
       "      <td>Citigroup identified risks related to the amou...</td>\n",
       "      <td>Citigroup identified risks related to the amou...</td>\n",
       "      <td>389</td>\n",
       "      <td>4</td>\n",
       "      <td>C_10K_2024.pdf</td>\n",
       "      <td>C</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did JPMorgan's net income change from 2023...</td>\n",
       "      <td>JPMorgan's net income increased from $49.6 bil...</td>\n",
       "      <td>JPMorgan's net income increased from $49.6 bil...</td>\n",
       "      <td>84</td>\n",
       "      <td>4</td>\n",
       "      <td>JPM_10K_2023.pdf</td>\n",
       "      <td>JPM</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is Bank of America's investment banking r...</td>\n",
       "      <td>Bank of America's investment banking revenue i...</td>\n",
       "      <td>Bank of America's investment banking revenue i...</td>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "      <td>JPM_10K_2023.pdf</td>\n",
       "      <td>JPM</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What was Citigroup's total assets in 2023?</td>\n",
       "      <td>Total assets for Citigroup in 2023 were $2,416...</td>\n",
       "      <td>Total assets for Citigroup in 2023 were $2,416...</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>C_10K_2024.pdf</td>\n",
       "      <td>C</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is JPMorgan's return on equity?</td>\n",
       "      <td>The return on equity for JPMorgan is 32%, 32%,...</td>\n",
       "      <td>The return on equity for JPMorgan is 32%, 32%,...</td>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "      <td>JPM_10K_2024.pdf</td>\n",
       "      <td>JPM</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What was Bank of America's net interest income...</td>\n",
       "      <td>$56,060 million</td>\n",
       "      <td>$56,060 million</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>BAC_10K_2024.pdf</td>\n",
       "      <td>BAC</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Compare JPMorgan and Bank of America's revenue...</td>\n",
       "      <td>JPMorgan's revenue growth from 2024 to 2025 wa...</td>\n",
       "      <td>JPMorgan's revenue growth from 2024 to 2025 wa...</td>\n",
       "      <td>141</td>\n",
       "      <td>4</td>\n",
       "      <td>JPM_10K_2024.pdf</td>\n",
       "      <td>JPM</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Which bank had higher trading revenue in 2024?</td>\n",
       "      <td>Bank of America had higher trading revenue in ...</td>\n",
       "      <td>Bank of America had higher trading revenue in ...</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>BAC_10K_2023.pdf</td>\n",
       "      <td>BAC</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0         What was JPMorgan's total revenue in 2024?   \n",
       "1  What are Bank of America's main business segme...   \n",
       "2  What risk factors did Citigroup identify in 2023?   \n",
       "3  How did JPMorgan's net income change from 2023...   \n",
       "4  What is Bank of America's investment banking r...   \n",
       "5         What was Citigroup's total assets in 2023?   \n",
       "6               What is JPMorgan's return on equity?   \n",
       "7  What was Bank of America's net interest income...   \n",
       "8  Compare JPMorgan and Bank of America's revenue...   \n",
       "9     Which bank had higher trading revenue in 2024?   \n",
       "\n",
       "                                              Answer  \\\n",
       "0                                   $224,532 million   \n",
       "1  Bank of America's main business segments are C...   \n",
       "2  Citigroup identified risks related to the amou...   \n",
       "3  JPMorgan's net income increased from $49.6 bil...   \n",
       "4  Bank of America's investment banking revenue i...   \n",
       "5  Total assets for Citigroup in 2023 were $2,416...   \n",
       "6  The return on equity for JPMorgan is 32%, 32%,...   \n",
       "7                                    $56,060 million   \n",
       "8  JPMorgan's revenue growth from 2024 to 2025 wa...   \n",
       "9  Bank of America had higher trading revenue in ...   \n",
       "\n",
       "                                         Answer_Full  Answer_Length  \\\n",
       "0                                   $224,532 million             16   \n",
       "1  Bank of America's main business segments are C...            144   \n",
       "2  Citigroup identified risks related to the amou...            389   \n",
       "3  JPMorgan's net income increased from $49.6 bil...             84   \n",
       "4  Bank of America's investment banking revenue i...             71   \n",
       "5  Total assets for Citigroup in 2023 were $2,416...             59   \n",
       "6  The return on equity for JPMorgan is 32%, 32%,...             85   \n",
       "7                                    $56,060 million             15   \n",
       "8  JPMorgan's revenue growth from 2024 to 2025 wa...            141   \n",
       "9  Bank of America had higher trading revenue in ...             51   \n",
       "\n",
       "   Num_Sources    Primary_Source Primary_Ticker Primary_Year  \n",
       "0            4  JPM_10K_2024.pdf            JPM         2024  \n",
       "1            4  BAC_10K_2024.pdf            BAC         2024  \n",
       "2            4    C_10K_2024.pdf              C         2024  \n",
       "3            4  JPM_10K_2023.pdf            JPM         2023  \n",
       "4            4  JPM_10K_2023.pdf            JPM         2023  \n",
       "5            4    C_10K_2024.pdf              C         2024  \n",
       "6            4  JPM_10K_2024.pdf            JPM         2024  \n",
       "7            4  BAC_10K_2024.pdf            BAC         2024  \n",
       "8            4  JPM_10K_2024.pdf            JPM         2024  \n",
       "9            4  BAC_10K_2023.pdf            BAC         2023  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "MORNING TASK: Track results in spreadsheet format\n",
    "\"\"\"\n",
    "\n",
    "# Combine all results\n",
    "all_results = simple_results + diverse_results\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame([\n",
    "    {\n",
    "        'Question': r['question'],\n",
    "        'Answer': r['answer'][:100] + '...' if len(r['answer']) > 100 else r['answer'],\n",
    "        'Answer_Full': r['answer'],\n",
    "        'Answer_Length': len(r['answer']),\n",
    "        'Num_Sources': len(r['sources']),\n",
    "        'Primary_Source': r['sources'][0]['file'] if r['sources'] else 'None',\n",
    "        'Primary_Ticker': r['sources'][0]['ticker'] if r['sources'] else 'None',\n",
    "        'Primary_Year': r['sources'][0]['year'] if r['sources'] else 'None'\n",
    "    }\n",
    "    for r in all_results\n",
    "])\n",
    "\n",
    "# Display summary\n",
    "print(f\"Results Summary:\")\n",
    "print(f\"  Total questions: {len(df)}\")\n",
    "print(f\"  Avg answer length: {df['Answer_Length'].mean():.0f} chars\")\n",
    "print(f\"  Avg sources per answer: {df['Num_Sources'].mean():.1f}\")\n",
    "print(f\"\\nFirst 10 results:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26bd5ddf-97f6-49b5-9b70-935b11a1ab38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Configuration (Baseline):\n",
      "  Chunk size: 800 chars\n",
      "  Chunk overlap: 150 chars\n",
      "  Retrieval k: 4 chunks\n",
      "\n",
      "We've tested 22 questions with this config\n",
      "Average answer length: 192 chars\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "AFTERNOON: Optimization Session\n",
    "First, let's establish our baseline (what we've been using)\n",
    "\"\"\"\n",
    "\n",
    "baseline_config = {\n",
    "    'chunk_size': 800,  # From yesterday's ingestion\n",
    "    'chunk_overlap': 150,\n",
    "    'k': 4\n",
    "}\n",
    "\n",
    "print(\"Current Configuration (Baseline):\")\n",
    "print(f\"  Chunk size: {baseline_config['chunk_size']} chars\")\n",
    "print(f\"  Chunk overlap: {baseline_config['chunk_overlap']} chars\")\n",
    "print(f\"  Retrieval k: {baseline_config['k']} chunks\")\n",
    "print(f\"\\nWe've tested {len(all_results)} questions with this config\")\n",
    "print(f\"Average answer length: {df['Answer_Length'].mean():.0f} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "585531f1-cc90-466d-9e0e-7f2384b88861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Testing k=3\n",
      "============================================================\n",
      "‚úì k=3: What was JPMorgan's total revenue in 2024?... ‚Üí 16 chars\n",
      "‚úì k=3: Compare JPMorgan and Bank of America's revenue gro... ‚Üí 226 chars\n",
      "‚úì k=3: What is Bank of America's investment banking reven... ‚Üí 14 chars\n",
      "\n",
      "============================================================\n",
      "Testing k=4\n",
      "============================================================\n",
      "‚úì k=4: What was JPMorgan's total revenue in 2024?... ‚Üí 16 chars\n",
      "‚úì k=4: Compare JPMorgan and Bank of America's revenue gro... ‚Üí 141 chars\n",
      "‚úì k=4: What is Bank of America's investment banking reven... ‚Üí 14 chars\n",
      "\n",
      "============================================================\n",
      "Testing k=5\n",
      "============================================================\n",
      "‚úì k=5: What was JPMorgan's total revenue in 2024?... ‚Üí 16 chars\n",
      "‚úì k=5: Compare JPMorgan and Bank of America's revenue gro... ‚Üí 116 chars\n",
      "‚úì k=5: What is Bank of America's investment banking reven... ‚Üí 71 chars\n",
      "\n",
      "‚úì Tested 3 questions √ó 3 k values = 9 total tests\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Experiment 1: Try k=3, 4, 5 (keeping chunk_size=800)\n",
    "Question: Does more context (higher k) improve answers?\n",
    "\"\"\"\n",
    "\n",
    "test_questions = [\n",
    "    \"What was JPMorgan's total revenue in 2024?\",\n",
    "    \"Compare JPMorgan and Bank of America's revenue growth\",\n",
    "    \"What is Bank of America's investment banking revenue?\"\n",
    "]\n",
    "\n",
    "k_experiments = []\n",
    "\n",
    "for k_val in [3, 4, 5]:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing k={k_val}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for q in test_questions:\n",
    "        result = ask_question(q, k=k_val, verbose=False)\n",
    "        k_experiments.append({\n",
    "            'k': k_val,\n",
    "            'question': q,\n",
    "            'answer': result['answer'],\n",
    "            'answer_length': len(result['answer']),\n",
    "            'num_sources': len(result['sources'])\n",
    "        })\n",
    "        print(f\"‚úì k={k_val}: {q[:50]}... ‚Üí {len(result['answer'])} chars\")\n",
    "\n",
    "print(f\"\\n‚úì Tested {len(test_questions)} questions √ó 3 k values = {len(k_experiments)} total tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fee539dc-86ee-4510-abcf-99bafc786791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Value Comparison:\n",
      "\n",
      "  answer_length        num_sources\n",
      "           mean    std       first\n",
      "k                                 \n",
      "3          85.3  121.8           3\n",
      "4          57.0   72.8           4\n",
      "5          67.7   50.1           5\n",
      "\n",
      "============================================================\n",
      "Analysis:\n",
      "============================================================\n",
      "k=3: Avg answer length = 85 chars\n",
      "k=4: Avg answer length = 57 chars\n",
      "k=5: Avg answer length = 68 chars\n",
      "\n",
      "Recommendation:\n",
      "- k=3: Fastest, but might miss context\n",
      "- k=4: Good balance (current baseline)\n",
      "- k=5: Most context, but potentially more noise\n",
      "\n",
      "‚Üí We'll stick with k=4 unless you see issues\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compare k values - which performs best?\n",
    "\"\"\"\n",
    "\n",
    "k_df = pd.DataFrame(k_experiments)\n",
    "\n",
    "print(\"K Value Comparison:\\n\")\n",
    "print(k_df.groupby('k').agg({\n",
    "    'answer_length': ['mean', 'std'],\n",
    "    'num_sources': 'first'\n",
    "}).round(1))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Analysis:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for k_val in [3, 4, 5]:\n",
    "    subset = k_df[k_df['k'] == k_val]\n",
    "    avg_len = subset['answer_length'].mean()\n",
    "    print(f\"k={k_val}: Avg answer length = {avg_len:.0f} chars\")\n",
    "\n",
    "print(\"\\nRecommendation:\")\n",
    "print(\"- k=3: Fastest, but might miss context\")\n",
    "print(\"- k=4: Good balance (current baseline)\")\n",
    "print(\"- k=5: Most context, but potentially more noise\")\n",
    "print(\"\\n‚Üí We'll stick with k=4 unless you see issues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8d53460-e2c7-4545-abfa-c80dba136353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Size Tradeoffs:\n",
      "\n",
      "\n",
      "600 characters:\n",
      "  ‚úÖ Pros: More precise retrieval, Less noise per chunk\n",
      "  ‚ùå Cons: Might split important context, Need more chunks (higher k)\n",
      "\n",
      "800 characters:\n",
      "  ‚úÖ Pros: Good balance, Captures full paragraphs, Current baseline\n",
      "  ‚ùå Cons: Moderate - balanced tradeoffs\n",
      "\n",
      "1000 characters:\n",
      "  ‚úÖ Pros: More context per chunk, Better for complex queries\n",
      "  ‚ùå Cons: Harder to find exact match, More noise\n",
      "\n",
      "============================================================\n",
      "DECISION: Keep 800 chars (our current setting)\n",
      "============================================================\n",
      "Why? It's been working well (good answers, correct sources)\n",
      "Re-ingesting just to test would take 10+ minutes\n",
      "Our baseline is solid!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Understanding Chunk Sizes:\n",
    "We created chunks yesterday with 800 chars. \n",
    "To test other sizes, we'd need to re-run ingestion.\n",
    "\n",
    "But let's understand the tradeoffs:\n",
    "\"\"\"\n",
    "\n",
    "print(\"Chunk Size Tradeoffs:\\n\")\n",
    "\n",
    "tradeoffs = {\n",
    "    600: {\n",
    "        'pros': ['More precise retrieval', 'Less noise per chunk'],\n",
    "        'cons': ['Might split important context', 'Need more chunks (higher k)']\n",
    "    },\n",
    "    800: {\n",
    "        'pros': ['Good balance', 'Captures full paragraphs', 'Current baseline'],\n",
    "        'cons': ['Moderate - balanced tradeoffs']\n",
    "    },\n",
    "    1000: {\n",
    "        'pros': ['More context per chunk', 'Better for complex queries'],\n",
    "        'cons': ['Harder to find exact match', 'More noise']\n",
    "    }\n",
    "}\n",
    "\n",
    "for size, info in tradeoffs.items():\n",
    "    print(f\"\\n{size} characters:\")\n",
    "    print(f\"  ‚úÖ Pros: {', '.join(info['pros'])}\")\n",
    "    print(f\"  ‚ùå Cons: {', '.join(info['cons'])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DECISION: Keep 800 chars (our current setting)\")\n",
    "print(\"=\"*60)\n",
    "print(\"Why? It's been working well (good answers, correct sources)\")\n",
    "print(\"Re-ingesting just to test would take 10+ minutes\")\n",
    "print(\"Our baseline is solid!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99c12c62-b08a-470b-85d1-c94919af4b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Metadata filtering function created!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9612b6e8-49c5-4135-84df-cbe154c9387b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Metadata filtering function created (FIXED)!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Experiment 2: Metadata Filtering (FIXED)\n",
    "Force retrieval to only search specific companies/years\n",
    "\"\"\"\n",
    "\n",
    "def ask_with_filter(question, ticker=None, year=None, k=4, verbose=True):\n",
    "    \"\"\"Ask question with metadata filtering\"\"\"\n",
    "    \n",
    "    # Build filter with ChromaDB syntax\n",
    "    filter_dict = None\n",
    "    \n",
    "    if ticker and year:\n",
    "        # Multiple filters need $and operator\n",
    "        filter_dict = {\n",
    "            \"$and\": [\n",
    "                {\"ticker\": ticker},\n",
    "                {\"year\": str(year)}\n",
    "            ]\n",
    "        }\n",
    "    elif ticker:\n",
    "        # Single filter\n",
    "        filter_dict = {\"ticker\": ticker}\n",
    "    elif year:\n",
    "        # Single filter\n",
    "        filter_dict = {\"year\": str(year)}\n",
    "    \n",
    "    # Create filtered retriever\n",
    "    if filter_dict:\n",
    "        retriever_filtered = vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": k, \"filter\": filter_dict}\n",
    "        )\n",
    "    else:\n",
    "        retriever_filtered = vectorstore.as_retriever(search_kwargs={\"k\": k})\n",
    "    \n",
    "    # Create chain\n",
    "    rag_chain_filtered = (\n",
    "        {\"context\": retriever_filtered | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    # Get answer\n",
    "    answer = rag_chain_filtered.invoke(question)\n",
    "    docs = retriever_filtered.invoke(question)\n",
    "    \n",
    "    if verbose:\n",
    "        filter_str = \"\"\n",
    "        if ticker or year:\n",
    "            filter_str = \" [Filter: \"\n",
    "            if ticker:\n",
    "                filter_str += f\"ticker={ticker} \"\n",
    "            if year:\n",
    "                filter_str += f\"year={year}\"\n",
    "            filter_str += \"]\"\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Q: {question}{filter_str}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"\\nA: {answer}\\n\")\n",
    "        print(\"Sources:\")\n",
    "        for i, doc in enumerate(docs):\n",
    "            print(f\"  [{i+1}] {doc.metadata.get('source_file')} \"\n",
    "                  f\"(Ticker: {doc.metadata.get('ticker')}, Year: {doc.metadata.get('year')})\")\n",
    "    \n",
    "    return {\n",
    "        'question': question,\n",
    "        'answer': answer,\n",
    "        'filters': filter_dict,\n",
    "        'sources': [{'file': doc.metadata.get('source_file'), \n",
    "                     'ticker': doc.metadata.get('ticker'),\n",
    "                     'year': doc.metadata.get('year')} for doc in docs]\n",
    "    }\n",
    "\n",
    "print(\"‚úì Metadata filtering function created (FIXED)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b1a65f3-1353-4d0f-a6b4-fec7f4abb920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FILTERING ANALYSIS\n",
      "============================================================\n",
      "\n",
      "1Ô∏è‚É£ WITHOUT FILTERING:\n",
      "   ‚úÖ Good for: Generic questions, comparisons across banks\n",
      "   ‚ùå Bad for: Specific company queries (might return wrong bank)\n",
      "   Example: 'What was the total revenue in 2024?' returned data from multiple banks\n",
      "\n",
      "2Ô∏è‚É£ WITH FILTERING:\n",
      "   ‚úÖ Good for: Specific company/year questions\n",
      "   ‚úÖ Guarantees: Sources match your filter\n",
      "   ‚ùå Trade-off: Less flexible, can't compare across banks\n",
      "   Example: Same question + filter ‚Üí precise results per bank\n",
      "\n",
      "============================================================\n",
      "RECOMMENDATION:\n",
      "============================================================\n",
      "- Use filtering when question mentions specific company/year\n",
      "- Use unfiltered for comparisons or general exploration\n",
      "- Could auto-detect: 'JPMorgan' in question ‚Üí add ticker=JPM filter\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Analysis: When should we use filtering?\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FILTERING ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ WITHOUT FILTERING:\")\n",
    "print(\"   ‚úÖ Good for: Generic questions, comparisons across banks\")\n",
    "print(\"   ‚ùå Bad for: Specific company queries (might return wrong bank)\")\n",
    "print(f\"   Example: '{test_q}' returned data from multiple banks\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ WITH FILTERING:\")\n",
    "print(\"   ‚úÖ Good for: Specific company/year questions\")\n",
    "print(\"   ‚úÖ Guarantees: Sources match your filter\")\n",
    "print(\"   ‚ùå Trade-off: Less flexible, can't compare across banks\")\n",
    "print(f\"   Example: Same question + filter ‚Üí precise results per bank\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RECOMMENDATION:\")\n",
    "print(\"=\"*60)\n",
    "print(\"- Use filtering when question mentions specific company/year\")\n",
    "print(\"- Use unfiltered for comparisons or general exploration\")\n",
    "print(\"- Could auto-detect: 'JPMorgan' in question ‚Üí add ticker=JPM filter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fc16843-3abb-4b28-b932-cc2dd486d6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing smart filtering:\n",
      "\n",
      "üîç Auto-detected filters: Ticker=JPM Year=2024\n",
      "\n",
      "============================================================\n",
      "Q: What was JPMorgan's revenue in 2024? [Filter: ticker=JPM year=2024]\n",
      "============================================================\n",
      "\n",
      "A: JPMorgan's revenue in 2024 was $177,556 million.\n",
      "\n",
      "Sources:\n",
      "  [1] JPM_10K_2024.pdf (Ticker: JPM, Year: 2024)\n",
      "  [2] JPM_10K_2024.pdf (Ticker: JPM, Year: 2024)\n",
      "  [3] JPM_10K_2024.pdf (Ticker: JPM, Year: 2024)\n",
      "  [4] JPM_10K_2024.pdf (Ticker: JPM, Year: 2024)\n",
      "\n",
      "\n",
      "üîç Auto-detected filters: Ticker=BAC \n",
      "\n",
      "============================================================\n",
      "Q: How did Bank of America perform? [Filter: ticker=BAC ]\n",
      "============================================================\n",
      "\n",
      "A: Bank of America's performance was positive, with revenue increasing by nine percent primarily driven by higher interest rates, as well as higher deposit and loan balances.\n",
      "\n",
      "Sources:\n",
      "  [1] BAC_10K_2023.pdf (Ticker: BAC, Year: 2023)\n",
      "  [2] BAC_10K_2022.pdf (Ticker: BAC, Year: 2022)\n",
      "  [3] BAC_10K_2022.pdf (Ticker: BAC, Year: 2022)\n",
      "  [4] BAC_10K_2024.pdf (Ticker: BAC, Year: 2024)\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "Q: Compare all three banks\n",
      "============================================================\n",
      "\n",
      "A: Based on the provided information, Bank of America, JPMorgan Chase, and the S&P Financials Index have all shown positive stock performance over the past five years. In terms of total assets, loans, deposits, and equity, Bank of America has the highest figures among the three. JPMorgan Chase has a higher number of employees compared to Bank of America. Additionally, JPMorgan Chase has a higher number of Global Private Bank client advisors. In terms of credit data and quality statistics, Bank of America has the highest net charge-offs, nonaccrual loans, and allowance for credit losses.\n",
      "\n",
      "Sources:\n",
      "  [1] BAC_10K_2022.pdf (Ticker: BAC, Year: 2022)\n",
      "  [2] JPM_10K_2023.pdf (Ticker: JPM, Year: 2023)\n",
      "  [3] JPM_10K_2024.pdf (Ticker: JPM, Year: 2024)\n",
      "  [4] JPM_10K_2024.pdf (Ticker: JPM, Year: 2024)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Smart filtering: Auto-detect company in question\n",
    "\"\"\"\n",
    "\n",
    "def smart_ask(question, k=4, verbose=True):\n",
    "    \"\"\"Automatically detect if question mentions specific company\"\"\"\n",
    "    \n",
    "    # Company name mappings\n",
    "    company_map = {\n",
    "        'jpmorgan': 'JPM',\n",
    "        'jpm': 'JPM',\n",
    "        'jp morgan': 'JPM',\n",
    "        'bank of america': 'BAC',\n",
    "        'bofa': 'BAC',\n",
    "        'bac': 'BAC',\n",
    "        'citigroup': 'C',\n",
    "        'citi': 'C'\n",
    "    }\n",
    "    \n",
    "    # Year detection (2022-2025)\n",
    "    year_detected = None\n",
    "    for year in [2022, 2023, 2024, 2025]:\n",
    "        if str(year) in question:\n",
    "            year_detected = year\n",
    "            break\n",
    "    \n",
    "    # Ticker detection\n",
    "    ticker_detected = None\n",
    "    question_lower = question.lower()\n",
    "    for name, ticker in company_map.items():\n",
    "        if name in question_lower:\n",
    "            ticker_detected = ticker\n",
    "            break\n",
    "    \n",
    "    # Use filtering if detected\n",
    "    if verbose and (ticker_detected or year_detected):\n",
    "        print(f\"üîç Auto-detected filters: \", end=\"\")\n",
    "        if ticker_detected:\n",
    "            print(f\"Ticker={ticker_detected} \", end=\"\")\n",
    "        if year_detected:\n",
    "            print(f\"Year={year_detected}\", end=\"\")\n",
    "        print()\n",
    "    \n",
    "    return ask_with_filter(question, ticker=ticker_detected, year=year_detected, k=k, verbose=verbose)\n",
    "\n",
    "# Test it!\n",
    "print(\"Testing smart filtering:\\n\")\n",
    "\n",
    "test_questions_smart = [\n",
    "    \"What was JPMorgan's revenue in 2024?\",  # Should filter JPM + 2024\n",
    "    \"How did Bank of America perform?\",       # Should filter BAC\n",
    "    \"Compare all three banks\",                # Should NOT filter\n",
    "]\n",
    "\n",
    "for q in test_questions_smart:\n",
    "    smart_ask(q, verbose=True)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da5a1fc2-3818-45d5-ba2f-5c418d9f3a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üèÜ FINAL OPTIMIZED CONFIGURATION\n",
      "============================================================\n",
      "\n",
      "üì¶ Chunking:\n",
      "  ‚Ä¢ Size: 800 chars\n",
      "  ‚Ä¢ Overlap: 150 chars\n",
      "  ‚Ä¢ Rationale: Good balance, captures full context\n",
      "\n",
      "üîç Retrieval:\n",
      "  ‚Ä¢ k value: 4 chunks\n",
      "  ‚Ä¢ Rationale: Enough context without noise\n",
      "\n",
      "üéØ Filtering:\n",
      "  ‚Ä¢ Strategy: smart (auto-detect company/year from question)\n",
      "  ‚Ä¢ Rationale: Improves precision for company-specific queries\n",
      "\n",
      "‚úÖ This configuration tested on 22+ questions with good results!\n",
      "\n",
      "üíæ Configuration saved to: data/processed/final_config.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Summary: Our optimal configuration\n",
    "\"\"\"\n",
    "\n",
    "final_config = {\n",
    "    'chunk_size': 800,\n",
    "    'chunk_overlap': 150,\n",
    "    'k': 4,\n",
    "    'filtering': 'smart (auto-detect company/year from question)'\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üèÜ FINAL OPTIMIZED CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüì¶ Chunking:\")\n",
    "print(f\"  ‚Ä¢ Size: {final_config['chunk_size']} chars\")\n",
    "print(f\"  ‚Ä¢ Overlap: {final_config['chunk_overlap']} chars\")\n",
    "print(f\"  ‚Ä¢ Rationale: Good balance, captures full context\")\n",
    "\n",
    "print(f\"\\nüîç Retrieval:\")\n",
    "print(f\"  ‚Ä¢ k value: {final_config['k']} chunks\")\n",
    "print(f\"  ‚Ä¢ Rationale: Enough context without noise\")\n",
    "\n",
    "print(f\"\\nüéØ Filtering:\")\n",
    "print(f\"  ‚Ä¢ Strategy: {final_config['filtering']}\")\n",
    "print(f\"  ‚Ä¢ Rationale: Improves precision for company-specific queries\")\n",
    "\n",
    "print(\"\\n‚úÖ This configuration tested on 22+ questions with good results!\")\n",
    "\n",
    "# Save configuration\n",
    "with open('../data/processed/final_config.json', 'w') as f:\n",
    "    json.dump(final_config, f, indent=2)\n",
    "\n",
    "print(\"\\nüíæ Configuration saved to: data/processed/final_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe06340f-f8f7-404c-b434-33cc23b0158e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Results saved!\n",
      "  ‚Ä¢ k_value_experiments.csv\n",
      "  ‚Ä¢ all_test_results.json\n",
      "  ‚Ä¢ final_config.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Save all afternoon experiment results\n",
    "\"\"\"\n",
    "\n",
    "# Save k experiments\n",
    "k_df.to_csv('../data/processed/k_value_experiments.csv', index=False)\n",
    "\n",
    "# Save all results (morning + afternoon)\n",
    "with open('../data/processed/all_test_results.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'baseline_results': all_results,\n",
    "        'k_experiments': k_experiments,\n",
    "        'config': final_config,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Results saved!\")\n",
    "print(\"  ‚Ä¢ k_value_experiments.csv\")\n",
    "print(\"  ‚Ä¢ all_test_results.json\")\n",
    "print(\"  ‚Ä¢ final_config.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (financial-rag)",
   "language": "python",
   "name": "financial-rag-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
